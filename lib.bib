% Encoding: UTF-8

@InProceedings{Brown2017,
  author    = {Cullen Brown and Ghanshyam Bhutra and Mohamed Suhail and Qinghong Xu and Eric D. Ragan},
  title     = {Coordinating attention and cooperation in multi-user virtual reality narratives},
  booktitle = {2017 IEEE Virtual Reality (VR)},
  year      = {2017},
  number    = {7892334},
  pages     = {377-378},
  month     = mar,
  abstract  = {Limited research has been performed attempting to handle multiuser storytelling environments in virtual reality. As such, a number of questions about handling story progression and maintaining user presence in a multi-user virtual environment have yet to be answered. We created a multi-user virtual reality story experience in which we intend to study a set of guided camera techniques and a set of gaze distractor techniques to determine how best to attract disparate users to the same story. Additionally, we describe our preliminary work and plans to study the effectiveness of these techniques, their effect on user presence, and generally how multiple users feel their actions affect the outcome of a story.},
  doi       = {10.1109/VR.2017.7892334},
  journal   = {Virtual Reality (VR), 2017 IEEE},
  keywords  = {user interfaces;virtual reality;gaze distractor techniques;guided camera techniques;multiuser storytelling environments;multiuser virtual reality narratives;multiuser virtual reality story experience;story progression;user attention;user cooperation;user presence;Cameras;Collaboration;Electronic mail;Face;Multimedia communication;Virtual environments;},
  url       = {http://ieeexplore.ieee.org/abstract/document/7892334/},
}

@Article{Monahan2008,
  author   = {Teresa Monahan and Gavin McArdle and Michela Bertolotto},
  title    = {Virtual reality for collaborative e-learning},
  journal  = {Computers \& Education},
  year     = {2008},
  volume   = {50},
  number   = {4},
  pages    = {1339 - 1353},
  issn     = {0360-1315},
  doi      = {http://dx.doi.org/10.1016/j.compedu.2006.12.008},
  keywords = {Cooperative/collaborative learning, Interactive learning environments, Lifelong learning, Multimedia/hypermedia systems, Virtual reality},
  url      = {http://www.sciencedirect.com/science/article/pii/S0360131506001989},
}

@InProceedings{Mueller2017,
  author    = {M\"{u}ller, Jens and R\"{a}dle, Roman and Reiterer, Harald},
  title     = {Remote Collaboration With Mixed Reality Displays: How Shared Virtual Landmarks Facilitate Spatial Referencing},
  booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
  year      = {2017},
  series    = {CHI '17},
  pages     = {6481--6486},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3025717},
  doi       = {10.1145/3025453.3025717},
  isbn      = {978-1-4503-4655-9},
  keywords  = {mixed reality, remote collaboration, virtual landmarks},
  location  = {Denver, Colorado, USA},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/3025453.3025717},
}

@InProceedings{Roo2017,
  author    = {J. S. Roo and M. Hachet},
  title     = {Towards a hybrid space combining Spatial Augmented Reality and virtual reality},
  booktitle = {2017 IEEE Symposium on 3D User Interfaces (3DUI)},
  year      = {2017},
  pages     = {195-198},
  month     = {March},
  abstract  = {Spatial Augmented Reality (SAR) allows a user, or a group of users, to benefit from digital augmentations embedded directly into the physical world. This enables co-located information and unobstructed interaction. On the other hand, SAR suffers from limitations that are inherently linked to its physical dependency, which is not the case for see-through or immersive displays. In this work, we explore how to facilitate the transition from SAR to VR, and vice versa, integrating both into a unified experience. We developed a set of interaction techniques and obtained first feedback from informal interviews.},
  doi       = {10.1109/3DUI.2017.7893339},
  keywords  = {augmented reality;SAR;hybrid space;immersive displays;interaction techniques;see-through displays;spatial augmented reality;virtual reality;Augmented reality;Buildings;Navigation;Resists;Three-dimensional displays;Tracking;3D Interaction;Augmented Reality;HMD;Mixed Reality},
}

@InProceedings{Elvezio2017,
  author    = {Elvezio, Carmine and Sukan, Mengu and Oda, Ohan and Feiner, Steven and Tversky, Barbara},
  title     = {Remote Collaboration in AR and VR Using Virtual Replicas},
  booktitle = {ACM SIGGRAPH 2017 VR Village},
  year      = {2017},
  series    = {SIGGRAPH '17},
  pages     = {13:1--13:2},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3089281},
  articleno = {13},
  doi       = {10.1145/3089269.3089281},
  isbn      = {978-1-4503-5013-6},
  keywords  = {3D referencing techniques, assembly, collaborative mixed/augmented reality, maintenance, remote guidance, remote task assistance},
  location  = {Los Angeles, California},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/3089269.3089281},
}

@InCollection{Herbelin2016,
  author      = {Herbelin, Bruno and Salomon, Roy and Serino, Andrea and Blanke, Olaf},
  title       = {Neural {M}echanisms of {B}odily {S}elf-{C}onsciousness and the {E}xperience of {P}resence in {V}irtual {R}eality},
  booktitle   = {Human {C}omputer {C}onfluence},
  publisher   = {De Gruyter},
  year        = {2016},
  editor      = {Gaggioli, Andrea and Ferscha, Alois and Riva, Giuseppe and Dunne, Stephen and Viaud-Delmon, Isabelle},
  series      = {De Gruyter Online},
  pages       = {80--96},
  abstract    = {Recent neuroscience research emphasizes the embodied
                 origins of the experience of the self. This chapter shows
                 that further advances in the understanding of the
                 phenomenon of VR-induced presence might be achieved in
                 connection with advances in the understanding of the
                 brain mechanisms of bodily self-consciousness. By
                 reviewing the neural mechanisms that make the virtual
                 reality experience possible and the neurocognitive models
                 of bodily self-consciousness, we highlight how the
                 development of applied human computer confluence
                 technologies and the fundamental scientific investigation
                 of bodily self-consciousness benefit from each other in a
                 symbiotic manner.},
  affiliation = {EPFL},
  details     = {http://infoscience.epfl.ch/record/220684},
  documenturl = {https://infoscience.epfl.ch/record/220684/files/[9783110471137 - Human Computer Confluence] 5. Neural Mechanisms of Bodily Self-Consciousness and the Experience of Presence in Virtual Reality.pdf},
  keywords    = {Human Computer Confluence; Virtual Reality; Cognitive Neuroscience; Self-consciousness; Presence},
  oai-id      = {oai:infoscience.epfl.ch:220684},
  oai-set     = {SV},
  status      = {PUBLISHED},
  submitter   = {146265; 146265},
  unit        = {CNP LNCO},
  url         = {http://www.degruyter.com/view/books/9783110471137/9783110471137-005/9783110471137-005.xml},
}

@Other{Wendrich2016,
  author        = {Wendrich, Robert E. and Chambers, Kris-Howard and Al-Halabi, Wadee and Seibel, Eric J. and Grevenstuk, Olaf and Ullman, David and Hoffman, Hunter G.},
  title         = {Hybrid Design Tools in a Social Virtual Reality Using Networked Oculus Rift: A Feasibility Study in Remote Real-Time Interaction},
  year          = {2016},
  __markedentry = {[dragvoll:6]},
  abstract      = {Hybrid Design Tool Environments (HDTE) allow designers and engineers to use real tangible tools and physical objects and/or artifacts to make and create real-time virtual representations and presentations on-the-fly. Manipulations of the real tangible objects (e.g., real wire mesh, clay, sketches, etc.) are translated into 2-D and/or 3-D digital CAD software and/or virtual instances. The HDTE is equipped with a Loosely Fitted Design Synthesizer (NXt-LFDS) to support this multi-user interaction and design processing. The current study explores for the first time, the feasibility of using a NXt-LFDS in a networked immersive multi-participant social virtual reality environment (VRE). Using Oculus Rift goggles and PC computers at each location linked via Skype, team members physically located in several countries had the illusion of being co-located in a single virtual world, where they used rawshaping technologies (RST) to design a woman’s purse in 3-D virtual representations. Hence, the possibility to print the purse out on the spot (i.e. anywhere within the networked loop) with a 2-D or 3D printer. Immersive affordable Virtual Reality (VR) technology (and 3-D AM) are in the process of becoming commercially available and widely used by mainstream consumers, a major development that could transform the collaborative design process. The results of the current feasibility study suggests that designing products may become considerably more individualized within collaborative multi-user settings and less inhibited during in the coming ‘Diamond Age’ [1] of VR, collaborative networks and with profound implications for the design (e.g. fashion) and engineering industry. This paper presents the proposed system architecture, a collaborative use-case scenario, and preliminary results of the interaction, coordination, cooperation, and communication with immersive VR.},
  comment       = {10.1115/DETC2016-59956},
  doi           = {10.1115/detc2016-59956},
  number        = {50084},
  pages         = {V01BT02A042},
  url           = {http://dx.doi.org/10.1115/DETC2016-59956},
}

@Article{Greenwald2017,
  author        = {Greenwald, Scott W. and Corning, Wiley and Maes, Pattie},
  title         = {Multi-User Framework for Collaboration and Co-Creation in Virtual Reality},
  journal       = {12th International Conference on Computer Supported Collaborative Learning (CSCL)},
  year          = {2017},
  __markedentry = {[dragvoll:6]},
  abstract      = {We present CocoVerse, a shared immersive virtual reality environment in which users interact with each other and create and manipulate virtual objects using a set of hand-based tools. Simple, intuitive interfaces make the application easy to use, and its flexible toolset facilitates constructivist and exploratory learning. The modular design of the system allows it to be easily customized for new room-scale applications.},
}

@Article{Pappas2006,
  author        = {Pappas, M. and Karabatsou, V. and Mavrikios, D. and Chryssolouris, G.},
  title         = {Development of a web-based collaboration platform for manufacturing product and process design evaluation using virtual reality techniques},
  journal       = {International Journal of Computer Integrated Manufacturing},
  year          = {2006},
  volume        = {19},
  number        = {8},
  pages         = {805--814},
  month         = dec,
  issn          = {0951-192X},
  __markedentry = {[dragvoll:6]},
  abstract      = {This paper describes the development of a web-based platform for collaborative process and product design evaluation. The distributed collaborative design evaluation (DiCoDEv) platform provides real-time collaboration of multiple users at different sites on the same project. The innovation concept of this platform lies in the use of virtual reality (VR) technology for the development of the working display environment that provides also navigation, immersion and interaction capabilities for all collaborative users in real time. The scope of this work is to provide an efficient robust collaboration tool for the real-time validation of a manufacturing product or process, from the early stages of the conceptual design until the latest stages of the production chain. In order to demonstrate the benefits of the virtual collaboration that DiCoDEv platform can provide for manufacturing, a pilot case with a VR environment has been developed based on the requirements of a ?real life? manufacturing company.},
  comment       = {doi: 10.1080/09511920600690426},
  doi           = {10.1080/09511920600690426},
  publisher     = {Taylor \& Francis},
  url           = {http://dx.doi.org/10.1080/09511920600690426},
}

@Comment{jabref-meta: databaseType:bibtex;}
