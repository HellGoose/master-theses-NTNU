\chapter{Results}
 The results where gathered through three phases: Phase one consisted of exploring Unreal Engine and the possibility for Hololens support for the Vive version of IVR-Connection. Due to findings in the first phase, the focus in the second phase changed to implementing IVR-Connection using the Unity Engine which has support for Hololens. The third phase then focused on improving the new implementation based on feedback gathered through testing.
 
    \section{Phase 1 Exploration}
    In the beginning of the first phase time was spent looking for ways to integrate Hololens into the already existing IVR-Connection application. To accomplish this, we had to look at the code of IVR-Connection and browse online for already existing solutions for Hololens in Unreal.
    
        \subsection{IVR-Connection}
        IVR-Connection was developed in 2016?, and used Unreal version 14.0, in relation to VR technology and especially Windows Mixed Reality, this could be considered as an old version of Unreal Engine. This meant that IVR-Connection needed an engine version update for it to be best able to support the newest VR technology, e.g. Hololens. We were tasked by our supervisors and stakeholders to update IVR-Connection to establish a stable baseline, a 1.0 release of IVR-Connection. This baseline was to act as the new official version that every other student working on the application would use. The aim was set at Unreal Engine release 4.18, as it provide a lot of new features and support for VR technology, making it a good version for a stable baseline for a VR application. Unfortunately it had no official support for Windows Mixed Reality and Hololens.
        
        Connect much stronger to EiT needs and learning goals!
        
        \subsection{Hololens Support}
        The best way to support Hololens, is to support UWP. Unreal engine did not natively support UWP at the time, but Microsoft were working on a branch of Unreal that did. This branch also had a sub branch called dev\_MixedReality which added support for Windows Mixed Reality. In addition there was a plugin called ProteusVR that added templates and blueprints for Hololens to this branch. ProteusVR had just reached version 1.0 and the lead developer promised to rapidly release updates as Windows' mixed reality branch evolved. The mixed reality sub branch did however not support Unreal engine 4.18 at the time. Since the priority for IVR-Connection was to support HTC Vive and be on the cutting edge of VR features, updating to Unreal engine 4.18 got prioritized over merging to the new Microsoft branch. In addition both the Microsoft branch and ProteusVR were both actively being developed. This meant that there was a chance for them both to catch up with 4.18 while we worked on the stable baseline for IVR-Connection. Thus Hololens support was set on hold until IVR-Connection 1.0 was finished.
        
        \subsection{VR Lab Space}
        
        Connect this to EiT learning goals (several students in VR together!)
        Early January, the VR lab at NTNU Dragvoll finished construction. The lab consisted of four Vive headsets in different booths in the same room, each with its own set of base stations. The VR booths had an open design: With one of the side open and openings at the top of the walls. This caused the the base stations' infrared light to bleed into the adjacent booths. This introduced issues with the spatial tracking for some of the Vive headsets. Several solutions were applied to fix this issue: 
        \begin{enumerate}
            \item Configure the base station in such a way that they could only one base station with a compatible setting.
            \item Using sync cables to ensure that the correct pair of base stations synced to each other.
            \item Stacking pieces of cardboard along the upper wall to block the light leaking over the wall.
            \item Putting cardboard boxes with one side open over the base stations to limit the angle that they were sending light.
            \item Using blinds to block any light entering through an opening in the side wall of one of the booths.
        \end{enumerate}
        
        The first fix was supposed to stop the base stations from syncing with the wrong base stations, this solution was not perfectly consistent however. The second fix was applied to address this issue, and this time the base stations consistently synced correctly to each other. The third fix stopped the light from leaking over the wall, effectively eliminating light leaks for some of the VR booths. Light bleeding from one booth to the other meant that the Vive headset would sometimes get confused about its spatial orientation. This had averse effects for the person wearing the headset, as the world would move around erratically, often causing nausea or dizziness. To further assure that no light was escaping over the wall, fix 4 was applied. Fix 5 had to be applied to one of the booths due to a hole in one of the side walls. With all the base stations syncing correctly and the light leaks fixed, the Vive headsets were now operating predictably. The issues experienced with having multiple Vive setups in the same room will according to HTC Vive's website be addressed with the 2.0 version of SteamVR and the 2.0 version of the base stations. % Some pictures for visualization, small, grouped side by side, in two rows if needed. Find a nice place to cite for 2.0. Best I found was the buy page, can we cite that? https://enterprise.vive.com/eu/
 
    \section{Phase 1 Implementation} % Fixing and updating to 4.18.
    The strategy for updating IVR-Connection to Unreal engine version 4.18 was carried out in two steps. Since 4.18 didn't get released before 23rd of October 2017, the first step was to update to 4.17. This was to be able to address as many deprecation issues as possible before 4.18 released, making the transition a little bit smoother. After 4.18 was released IVR-Connection was updated again, bringing it up to date with the newest VR features Unreal could offer. % Ref 4.18 release date blog post containing list of new features? https://www.unrealengine.com/en-US/blog/unreal-engine-4-18-released
        
        \subsection{Plugins}
        There were two plugins attached to the original version of IVR-Connection: VR Expansion and that other one. VR Expansion Released updates for 4.17 and eventually 4.18, so we did not need to modify anything using this plugin. That other one one the other hand seemed to be dead, and had not released any updates in a while. We therefore removed the plugin and rewrote the blueprints that had been using it. This was done with native functions within the Unreal engine. % Find name and exact date for last version of the other plugin.
        
        \subsection{Image Loading}
        The blueprints for loading and sharing images used features from the removed plugin which had no equal within the Unreal engine. Loading images had also previously proved to freeze the main thread while the image was being loaded. The solution to both these issues were finding a small piece of code that allowed for loading the images asynchronous to the main thread. % Ref code source + picture or code snippet?
    
    
    \section{Phase 1 Evaluation} % Internal Evaluation, What made us change
    The evaluation of phase 1 consisted of 1 survey with 26 respondents and an internal evaluation regarding Hololens and Unreal.
    
        \subsection{Survey} % UKA questionnaire
        The survey were a part of a stand at UKA technology conference, were people could come and test IVR-Connection for Vive before filling it out. The goal was to get an idea of what people think about using VR for collaboration and learning, as well as to get an overview of what features the respondents deemed most important in such a scenario.
        
        Of the total 26 respondents, 46.2\% had tried VR a few times before while only 11.5\% had tried it many times, which leaves 42.3\% that had never tried VR before that day. Because the definition of many and a few can vary from person to person, it only makes sense to make a distinction between those who had tried VR before, and those that had not.
        
        The survey showed that interacting together in VR can be an exciting and engaging experience, since all respondents agreed to this. Which is reflected in their excitement about the idea of using this for collaboration and lectures in the future. In other words, the survey confirmed that the concept of IVR-Connection was worth continuing on.
        
        24 of the total 26 respondents said that they felt a strong or some sense of presence in the VR world, but only 11 agreed that it was easy to follow what the others were doing. When observing the respondents trying IVR-Connection, an emerging trend was that they lost track of the other users when they were teleporting. This might indicate that the application needs some features for tracking the other users location, e.g. adding spatial sounds and/or particle trails when people are teleporting.
        
        % TODO: avsnitt om features
        
        \subsection{Hololens} % Lacking Hololens support for Unreal
        By the end of the first phase the mixed reality branch of Unreal developed by Microsoft were still stuck in 4.16, and ProteusVR had not seen any activity in 4 months. This meant that we either had to switch back to Unreal 4.16 or find another way of using Hololens for a collaborative environment.
        
        Switching back to 4.16 and using Microsoft's Unreal branch, could make it unnecessarily complicated for the other students working on the project. As well as limiting development when it comes to supporting the newest standards and VR hardware optimally. Thus we decided not to continue down the path to add Hololens support for IVR-Connection for Vive.
        
        Instead we directed our attention towards Unity. Unity offered support for the newest in VR hardware and was Microsoft's own recommended engine for developing 3D applications for Hololens and Windows Mixed Reality. To further accelerate development Microsoft had also started working on a plugin, called Holotoolkit. This tool was developed as an open source project and had a high level of activity, which meant relatively frequent updates. In addition making our own software, meant more freedom to explore in the directions we wanted. Thus we opted to take the concept of IVR-Connection and implement it with Hololens support in Unity. % https://docs.microsoft.com/en-us/windows/mixed-reality/development-overview
        
    \section{Phase 2 Requirements}
    For the second phase, requirements where elicited based on the results of the UKA questionnaire from phase 1 combined with personal experiences with collaboration in VR. This section lists these requirements.
    
    Should be explained much better how the requirements are derived from the EiT learning goals, the need for facilitating and theory, e.g. immersion and social presence
    
        \subsection{F1 - VR/MR? Collaboration Space}
        The user should be able to enter a collaborative space. The collaborative space should have the following features:
        \begin{enumerate}
            \item The space must feel roomy and spacious at the same time.
            \item The space must function as a collaborative space, e.g not be too fancy or captivating.  "supporting sense of presence?"
            \item The space must be easy to navigate, e.g. have objects placed about to give you a sense of depth.
        \end{enumerate}
        
        \subsection{F2 - Avatar}
        The user should have an avatar that represents him/her in the virtual space. The avatar should have the following features:
        \begin{enumerate}
            \item The avatar should follow the movement of the player.Identity? Social presence
            \item There should be 2 different avatars. One for immersed headsets and one for the hololens.
        \end{enumerate}
        
        \subsection{F3 - Movement}
        The user should be able to move around in the virtual space. The movement should be governed by the following features:
        \begin{enumerate}
            \item The user must be able to walk around in the virtual environment by walking around in the real world.
            \item The user must be able to teleport using a controller.
        \end{enumerate}
        
        \subsection{F4 - Multiplayer}
        The user should be able to connect to other users. The multiplayer system should contain the following features:
        \begin{enumerate}
            \item The user should be able to host a session from any supported device.
            \item The user should be able to search for active sessions created by other users.
            \item The user should be able to join an active session.
            \item The user should be able to disconnect from the currently active session.
        \end{enumerate}
        
        \subsection{F5 - Drawing}
        The user should be able to communicate and visualize through drawing. The drawing should be governed by the following features:
        \begin{enumerate}
            \item The user should be able to draw on a surface.
            \item The user should be able to draw in the air in 3 dimensions.
            \item The user should be able to choose a color to draw with.
            \item The user should be able to erase what has been drawn.
        \end{enumerate}
        
        \subsection{F6 - Media Sharing}
        The user should be able to share media like video and images to other users. The sharing of media should be governed by the following features:
        \begin{enumerate}
            \item The user should be able to open a sharing menu.
            \item From the sharing menu the user should be able to share media with the other users.
            \item When shared, a game object representing the media should be spawned in the virtual space.
            \item The user should be able to move the spawned game object.
        \end{enumerate}
        
        \subsection{F7 - Voice Chat}
        The user should be able to communicate by using a voice chat. The voice chat should contain the following features:
        \begin{enumerate}
            \item The user should be able to speak to other users using a microphone.
            \item When a user speaks there should be an indication of it in the virtual space.
            \item The voice chat should be activated as soon as a user hosts a session.
        \end{enumerate}
        
        \subsection{F8 - Interactable Objects}
        The user should be able to play around with physically intractable objects in the virtual space. These objects should have the following features:
        \begin{enumerate}
            \item The user should be able to pick up the object.
            \item The user should be able to throw the object.
            \item When thrown the object should maintain momentum according to the physical laws of the virtual space.
        \end{enumerate}
        
        \subsection{F9 - Hololens Spectating}
        The user should be able to spectate the virtual space by using a Hololens. Using the Hololens should be governed by the following features:
        \begin{enumerate}
            \item The user should be able to move the virtual collaborative space.
            \item The collaborative space should be moved relative to the real world, e.g. can be place on a table or on the floor.
            \item When using the Hololens the virtual space should appear small enough to fit on a table.
        \end{enumerate}
    
    \section{Phase 2 Implementation} % Implementation of IVR-Connection in Unity. Based on requirements.
    For the second phase not all requirements where met. Only the most essential features to complete a proof of concept test where implemented. The rest of this section will list and describe these features.
    
        \subsection{Collaboration Space}
        The collaboration space is the playing area where the immersed players can move around and interact with each other and the environment. It is designed to meet requirement F1. It has some boxes placed about to make it feel less empty, and a big whiteboard where the immersed players can draw. Attached to gameobject is a LevelLogic script. It contains the logic for how the different headset types should spawn and scale the collaboration space. % Add picture. Not much more to say?
        
        \subsection{Avatar}
        The avatar consists of a model with a PlayerController script attached, and was designed to meet requirement F2 and F3. The PlayerController script contains all the logic for how the player can interact with the virtual world. Due to lack of 3D modelling skills and time, the model for the avatar were taken from Microsoft's 250 Mixed Reality tutorial. The model is under the MIT licence. % Pictures and ref to the tutorial
    
        \subsection{Match Maker}
        The match maker is based on Unity's match making system using UNET and HoloToolkit's example menu. The match maker contains logic for creating, searching for and joining matches and was extended to be able to transmit room data from Hololens to Hololens. The UI follows the player around and anchors around the bottom of the viewport. It only supported creating and joining matches. The join button where for testing purposes hard coded to search for matches, and then join the first match it found. The match maker was implemented to meet requirement F4. % Pictures
        
        \subsection{Drawing}
        Drawing was implemented by giving the player a pen and a palette. The pen is used to draw on the whiteboard in the collaboration space. This is done by pointing the colored tip towards the whiteboard and drag it around, just like in the real world. The palette is used to change color. The player can change the color of the pen by touching the colors on the palette with the tip of the pen.  % Pictures + something about the code?
        
        \subsection{Hololens Spectating}
        Joining or creating a session while using a Hololens gives you a birds eye view of the collaboration space. Upon joining or creating a session, the collaboration space will spawn relative to you and your physical environment. The player can move the collaboration space by doing a tap gesture to pick it up, and another tap gesture to place it down again. The collaboration space will align with the spatial data gathered by the Hololens. If someone with an immersed headset joins the session, they will appear in the collaboration space. The Hololens will thus be able to observe the interactions of those with the immersed headsets. Hololens spectating was implemented according to requirement F9.
    
    \section{Phase 2 Evaluation}
    The evaluation of phase 2 consisted of one user test with 7 EiT students and 5 facilitators followed by a focus group session with 2 of the facilitators, and a survey for all 12 of them.
    Due to some bugs in the network code, the multiplayer and cooperation aspect fell out of focus, and only the individual features where properly tested. This means that only the concept of the application and the individual features were evaluated.
    
    \com{5 facilitators here but 2 in the next sections? Confusing, explain the settings better, in a separate subsection!}
    
        \subsection{Survey} % Summary of survey data.
        This subsection will contain a summery of the survey data.
        % Purpose
        
        % VR collab and outside
        
        % Physical lab space
        
        % EiT course, not relevant?
        
        % Vive Application
        
        % Mixed Reality Application
        
        % Facilitators
        
        \subsection{Mixed Reality Application Concept} % Summary of interview. Relevant to Mixed Reality.
        % TODO: Connect with requirements.
        The same two facilitators didn't get to do a full test in the Mixed Reality version due to some technical difficulties. But both looked at the concept and a demo with the Hololens. The paragraphs below is a summary of what was said and discussed.
        
        The avatar for the Hololens was too big and intrusive. It is important that the facilitators doesn't take all the attention of the room, but rather acts as a fly on the wall. At least when you are observing. When you are about to give feedback, having a feature that temporarily makes you able to acquire the students attention would be nice. Like for example descending down into their world with a gesture or another in-game indicator that make them understand that you want their attention. It is important that this is comfortable for the students.
        
        The facilitators suggested that it would be nice to be able to write on the whiteboard while spectating as Hololens. By adding this feature the facilitator could explain both verbally and visually, and interact with what the students have written themselves. Especially useful for doing EiT exercises.
        
        Even less body language to observe in this version. The application had only avatars with a moving body and a rotating head. No indicator for speech and no hands for gesticulating.
        
        The facilitators also suggested adding the ability to import documents and write on them. This to be able to implement some EiT form exercises into the application. One way to do this is by implementing the ability to import images and draw on them. Making the user able to mark of on forms and saving the result for inspection by the facilitators.
        
        \subsection{Vive Application} % Summary of interview. Relevant to Vive application
        % TODO: Connect with requirements.
        Was tested by two facilitators. One with and one without the Vive headset which both had pros and cons. The following paragraphs is a summary of what were said and discussed in this interview.
        
        The VR lab enabled one facilitator to watch the Trondheim side of the collaboration via the screens in the room. This required a lot of concentration and ended up being tiresome. It felt a little like watching TV and thus he felt more distant than usual when trying to facilitate. Watching through the participants eyes he only got to see what they were looking at, and trying to follow 4 screens looking for collaborative elements was hard. Especially since the level of body language he could read were limited, although he could see 3 of the participants in the room with him, their faces where obscured by the Vive headset. The hardware and equipment also posed limitations, especially on the Gjøvik side, since they only had one phone acting as a microphone. This generated a lot of noise, making it somewhat hard to follow conversations. The threshold for giving feedback and suggestions were higher, since his presence were only heard and not seen. The students completed an EiT exercises name "take space, give space". 
        \com{More details here!}
        
        
        Due to technical and software limitations this took a lot more time in VR than in the real world. Making it more effort than gain. He also noted that using Skype or another VOIP application with a video feed might have been more efficient for this type of exercises, at leas for this version of the IVR-Collaboration.
        
        The other facilitator tried facilitating with the Vive headset and found that using VR can be uncomfortable and nauseating. For example when the headset picks up signals from the wrong base station, it will get confused and throw you around in the world. She also pointed out that it was hard to pick up on body language and was missing facial expressions, as these are signs she usually picks up on when facilitating in the real world. She also experienced that the VR world had a lot of unrelated stimuli. There is always something more interesting to look at, especially the first times you try it. And since the audio is only in their head, the visual stimuli might at times take more of your focus than intended. In other words, it might be harder to pay attention to what people are saying.
        
        Approximately 70\% of communication comes from body language. And the body language the EiT students used were very different from what the facilitators had observed outside of VR. The facilitators speculated that this could be due to another group dynamic when collaborating with Gjøvik in contrast to internally with each other. They also speculated that it could be due to the anonymity of the session. Especially when someone is talking and not referring to anything in the world, the students tended to look at their hands or pay attention to something else, at least visually. Another factor might be that this is an application that is part of a test project that the EiT students didn't choose to use themselves. It has a lot of bugs and technical difficulties so the facilitators speculated that this could give them an "get it over with" mentality and make them not take it seriously.
        
        Avatars and anonymity can be good for racial and gender bias, as neither of them are visually visible in the application. The facilitators agreed that keeping this feature could be good for inclusion and equality. But that it is still important to be able to distinguish between the different participants, and that name tags can be a good candidate for this. The facilitators also agreed that the avatars should match the purpose. For example do not use animals or crazy outfits for a normal meeting session.
        
        Long session in VR can be tiresome and induce nausea for many different reason. One thing the facilitators noted was that they found it strange that the students decided to stand during whole length of the meeting. This might be due to you not being able to see the chair beside you inside the VR world.
        
        \subsection{Requirements} % F1 - 5 partially fulfilled, F6 - 8 not fulfilled, F9 almost fulfilled.
        This subsection will contain discussion around how the requirements have or have not been met for phase 2.
        
        For phase 2 not all requirements were met. Requirement F1, F2, F4 and F5 were partially met and F6 - F8 were not met at all. Requirement F9 was met, but lacked some specification that were added for phase 3, and requirement F3 was completely met. The rest of this section will briefly discuss the fulfillment of each requirement.
        
        For requirement F1 it was hard to determine if it was met or not. Requirement F1.1 and F1.2 were too unspecific and hard to understand what was actually required. Requirement F1.3 seems to have been met, since none of the test participants had any trouble navigating the environment. To test this case thoroughly, it would also be required to test the application with people less experienced with VR.
        
        The Avatar followed the player as describe in requirement F2.1, but did not have a separate avatar for Hololens as required by F2.2. This was due to F2.2 being of low priority when critical bugs were still present right before the test was conducted. Requirement F2 also lacked the specification for the two different avatars.
        
        The requirement F3 were met. The player can move around by walking in the real world as describe by F3.1 and teleport using a controller as describe by F3.2. The player is thus able to move around in the virtual space.
        
        Multiplayer was very unstable for phase 2, but the requirements were almost met anyways due to lacking specifications for stability and long levity. These specification had to be added in phase 3 for a correct measure of working multiplayer functionality. Aside from that the requirements F4.1, F4.2, F4.3 were all completely met through the implemented match maker. Requirement F4.4 were however not met due to the lack of a disconnect feature, apart from forcibly closing the application by external means.
        
        The Drawing functionality almost met the requirements specified in F5. Through a pen and a palette the player were able to draw on a surface (the whiteboard) as specified by F5.1 and choose a color by using the palette as required by F5.3. To be able to erase what had been drawn and thus fulfilling requirement F5.4, the player could select the color white, which was the same white as the whiteboard. Drawing in 3D as described by F5.2 was not fulfilled and was also set to a low priority for phase 3. The render method used for drawing also caused a lot of frame rate drops for Hololens, thus requirements regarding performance had to be added for phase 3.
        
        Requirement F6 - F8 were, as mention earlier, not fulfilled at all. Mostly because these were giving a lower priority than the rest of the requirements. Requirement F6 describes sharing media. This feature were implemented through image sharing with limited functionality, but were left out because it was difficult and complex to use, and due to the lack of a proper UI implementation. Requirement F7 described voice chat. The voice chat functionality were given a lower priority due to the expected problems with limited bandwidth through Unity's network service, and because using a third-party software was just as viable. Requirement F8 described intractable objects and were given a low priority due to the low impact it would have on the completed product.
        
        Requirement F9 were met for phase 2. The player was able to spectate the virtual space by using the Hololens, as well as move the collaboration space relative to the real world as specified by requirement F9.1 and F9.2. The collaboration space fit on a table as describe by requirement F9.3, but the interviews revealed that it was to small to follow what the immersed players were doing. Thus further specifications were needed for in phase 3.
        
        
    \section{Phase 3 Updated Requirements} % Only write changes to requirements here. Alt title: Phase 2 Changes to Requirements.
    For phase 3 it was necessary to update the requirements from phase 2. The updated requirements are mainly based on the interviews with the facilitators. The updated requirements are listed in this section.
    
        \subsection{F1 - VR Collaboration Space} % Write about changes to the requirements, and then display them. Might make a table for requirements.
        No big changes were done to this requirement. F1.1 and F1.2 were rewritten to make more sense and be more precise, without changing the underlying meaning. The updated requirement is shown below.
        \newline\newline
        The user should be able to enter a collaborative space. he collaborative space should have the following features:
        \begin{enumerate}
            \item The space must not be too big, and at the same time it must be spacious enough to not feel cramped.
            \item The space must function as a collaborative space and not be too fancy or captivating, as this might draw attention away from the task at hand.
            \item The space must be easy to navigate, e.g. have objects placed about to give you a sense of depth.
        \end{enumerate}
        
        \subsection{F2 - Avatar}
        For the avatar two additional requirements were added to make a distinction between the avatar for Hololens and the avatar for immersed headsets. F2.3 describes the immersed avatar and F2.4 describes the Hololens avatar. The updated requirement is shown below.
        \newline\newline
        The user should have an avatar that represents him/her in the virtual space. The avatar should have the following features:
        \begin{enumerate}
            \item The avatar should follow the movement of the player.
            \item There should be 2 different avatars. One for immersed headsets and one for the hololens.
            \item The Immersed avatar should have a body, a head and two hands.
            \item The Hololens avatar only needs a head.
        \end{enumerate}
        
        \subsection{F3 - Movement}
        No changes were made to this requirement.
        
        \subsection{F4 - Multiplayer}
        For multiplayer two new requirements were added to specify the minimum requirements for the stability and capacity of a session. F4.5 describes stabilty and F4.6 describes capacity.
        \newline\newline
        The user should be able to connect to other users. The multiplayer system should contain the following features:
        \begin{enumerate}
            \item The user should be able to host a session from any supported device.
            \item The user should be able to search for active sessions created by other users.
            \item The user should be able to join an active session.
            \item The user should be able to disconnect from the currently active session.
            \item A session should be stable and optimized for sessions lasting 30 minutes or more.
            \item A session should support a minimum of 4 simultaneous users.
        \end{enumerate}
        
        \subsection{F5 - Drawing}
        For drawing one new requirement were added to specify how much impact drawing can be allowed to have on the frame rate.
        \newline\newline
        The user should be able to communicate and visualize through drawing. The drawing should be governed by the following features:
        \begin{enumerate}
            \item The user should be able to draw on a surface.
            \item The user should be able to draw in the air in 3 dimensions.
            \item The user should be able to choose a color to draw with.
            \item The user should be able to erase what has been drawn.
            \item Drawing should not lower the frame rate of the application with more than 10 frames.
        \end{enumerate}
        
        \subsection{F6 - Media Sharing}
        No changes were made to this requirement.
        
        \subsection{F7 - Voice Chat}
        No changes were made to this requirement.
        
        \subsection{F8 - Interactable Objects}
        No changes were made to this requirement.
        
        \subsection{F9 - Hololens Spectating}
        For Hololens spectating one requirement was updated and 3 were added. Requirement F9.3 were changed to reflect the new requirement F9.4. F9.4 describes the users ability to be able to scale the collaboration space. Requirements F9.5 and F9.6 describes a personal whiteboard for the Hololens spectator.
        \newline\newline
        The user should be able to spectate the virtual space by using a Hololens. Using the Hololens should be governed by the following features:
        \begin{enumerate}
            \item The user should be able to move the virtual collaborative space.
            \item The collaborative space should be moved relative to the real world, e.g. can be place on a table or on the floor.
            \item The starting scale of the collaborative space should appear small enough to fit on a table.
            \item The user should be able to scale the collaborative space.
            \item The user should have its own personal whiteboard that can be scaled and moved in the same manor as the collaborative space.
            \item The personal whiteboard should replicate what is drawn on the whiteboard in the collaborative space.
        \end{enumerate}
    
    
    \section{Phase 3 Implementation} % Improving IVR-Connection for Unity. Stability, features, optimization. Based on feedback and remaining unfulfilled requirements.
    During phase 3 improvements were made toward having a more stable and complete product based on the update requirements. This section lists the different features implemented and explains what was created and updated.
    
        \subsection{Collaboration Space}
        The collaboration was scaled to fit the height of the user better. To do this the overall height of the space were brought down and the width made a little smaller. On the scripting end, LevelLogic.cs now makes sure that both the scale and position of the space is synced relative to the avatars. This ensured that every player gets the same and correct state of the world.
        
        \subsection{Avatar}
        The Avatar were scaled to match the new scale of the collaboration space, and to fit better relating to the headset user and the ground. The goal of the new scale is to make it easier to feel immersed in the space. split into two different game objects. One for Hololens players and one for immersed headset players. This was to make it easier to develop individual features for the different hardware.
        
        The Hololens avatar is now a cloud in the sky. This was to make the spectator less intrusive to the once collaborating in the space, while at the same time being able to draw attention if needed. The cloud model were taken from Microsoft's 250 mixed reality tutorial.
        
        The immersed avatar now has a pair of hands in addition to the body and the head. The hands will follow the movement of the motion controllers used with the immersed headset. If no controllers are connected, the hands will be hidden. A speech indicator were also added to let the other players see when someone with an immersed headset is talking. The speech indicator consists of a red ball over the players head. The red ball will be visible when the player speaks, and hide itself otherwise.
        
        A name tag were added for both avatars. The name can be set in the menu before you join or create a session, and will hover above the players head. The name will help the players keep track of who's who. % Add some pictures of this.
    
        \subsection{Match Maker}
        The UI of the match maker were moved closer. This was to make it easier to read the labels on the buttons. A search button were added to let the player search for matches before joining. This was added to make the application ready to handle multiple sessions at the same time. When the player search for a match, any session found will be displayed above the buttons in a list. The player can then select the session and click join to join the selected session.
        
        The network code were optimized to send less data per second. This was needed due to the low bandwidth limit put in place by Unity's networking service. To accomplish this all networked messages were forced to only happen a certain amount per second. Ranging from a couple to 30 times per second. This still wasn't really enough to keep within the limits. To properly fix this issue, we would need to either start paying for Unity Pro and Unity's network service, or implement another network system. None of these options were really valid. Unity Pro and its network services costs a lot of money, and implementing a new network system would have taken more time than was available. In the end we chose to move on because the application now run just long enough to do a multiplayer test.
        
        \subsection{Drawing}
        Due to the network optimizations the drawing feature had to be tweaked. The drawing data that had to be synced between clients were reduced to the smallest possible type. This resulted in the color scheme for drawing now only supports 256 different colors, but for most practical purposes this should be enough to use the whiteboard effectively.
        
        The drawing process also had to be optimized due to limited processor power on the Hololens. To accomplish this the logic of applying draw data to the whiteboard texture were separated from the draw logic itself. Because applying data to a texture is a CPU heavy task, this allowed us to reduce the CPU load by applying data less often. With the immersed headsets this was not an issue and thus they could continue to apply data as fast as they were drawing, but for the Hololens the frequency were lowered to 10 times per second. 
        
        Lowering the frequency to 10 times per second, synced the drawings on the whiteboard frequently enough to effectively follow what the other players were drawing. It also reduced the load on the CPU significantly, but the spikes generated still caused low frame rates when run on the Hololens. The solution to this could be to use a shader for drawing on the whiteboard texture. A shader would move the work load from the CPU to GPU, which is much more optimized to handle such tasks. Even though this might have been a good solution, we lacked shader competence and time to learn and implement it properly. Resulting in any further optimization effort to be put on hold. In the mean time the application could be streamed from the computer to the Hololens, effectively working around the issue.
        
        \subsection{Hololens Spectating}
        The scale of the world as the Hololens sees it were scaled up. This was to make it easier to follow what the immersed player where doing in the collaborations space. A bigger extra whiteboard that only the Hololens can see was also added. This whiteboard can be moved around and placed relative to the real world, just like the collaboration space. This new whiteboard replicates what is drawn on the original whiteboard. This is to make it easier for the Hololens user to see what is being drawn.
        
        Because of the issues with drawing and network service, the Hololens cannot effectively run the application on its own. A computer with Unity engine version 2017.2p1 and the source code from Git is needed. With Unity open you can stream the application to the Hololens while letting the computer do all the heavy lifting. At the same time the Hololens can still use gestures and gaze controls to interact with the application. Thus this work around let us test Hololens spectating without having to worry about limited hardware resources.
    
    \section{Phase 3 Evaluation} % This might get its own chapter
    The evaluation for phase three consisted of one user test with two VR experts and a facilitator, followed up by a focus group session. In the test the VR experts were told to cooperate to complete a drawing challenge while the facilitator observed and took notes of how they cooperated. The goal of the test was for the facilitator to evaluate if using Hololens for observing cooperation in VR gives any advantages when trying to facilitate.
        
        \subsection{Focus Group Feedback}
        This subsection will contain a summary of the focus group evaluation with relations to observations made internally and during the test.
        
        \subsection{Requirements}
        This subsection will contain discussion around how the requirements have or have not been met for phase 3.
        
        
        
        
        
        